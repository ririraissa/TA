{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"TENSORFLOW_DATA.csv\")\n",
    "df_test = pd.read_csv(\"TENSORFLOW_TES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(p) R</th>\n",
       "      <th>R (2)</th>\n",
       "      <th>R (5)</th>\n",
       "      <th>(p) G</th>\n",
       "      <th>G (2)</th>\n",
       "      <th>G (5)</th>\n",
       "      <th>(p) B</th>\n",
       "      <th>B (2)</th>\n",
       "      <th>B (5)</th>\n",
       "      <th>(p) GreyScale</th>\n",
       "      <th>GreyScale (2)</th>\n",
       "      <th>GreyScale (5)</th>\n",
       "      <th>garut</th>\n",
       "      <th>solo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>133</td>\n",
       "      <td>135</td>\n",
       "      <td>131</td>\n",
       "      <td>156</td>\n",
       "      <td>159</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>141</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>231</td>\n",
       "      <td>243</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>243</td>\n",
       "      <td>225</td>\n",
       "      <td>228</td>\n",
       "      <td>241</td>\n",
       "      <td>212</td>\n",
       "      <td>231</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209</td>\n",
       "      <td>214</td>\n",
       "      <td>225</td>\n",
       "      <td>209</td>\n",
       "      <td>118</td>\n",
       "      <td>134</td>\n",
       "      <td>224</td>\n",
       "      <td>151</td>\n",
       "      <td>168</td>\n",
       "      <td>204</td>\n",
       "      <td>150</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>202</td>\n",
       "      <td>220</td>\n",
       "      <td>144</td>\n",
       "      <td>214</td>\n",
       "      <td>234</td>\n",
       "      <td>138</td>\n",
       "      <td>206</td>\n",
       "      <td>228</td>\n",
       "      <td>140</td>\n",
       "      <td>210</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>225</td>\n",
       "      <td>205</td>\n",
       "      <td>213</td>\n",
       "      <td>101</td>\n",
       "      <td>207</td>\n",
       "      <td>214</td>\n",
       "      <td>142</td>\n",
       "      <td>211</td>\n",
       "      <td>217</td>\n",
       "      <td>223</td>\n",
       "      <td>207</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>216</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>217</td>\n",
       "      <td>105</td>\n",
       "      <td>99</td>\n",
       "      <td>220</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>216</td>\n",
       "      <td>103</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175</td>\n",
       "      <td>96</td>\n",
       "      <td>117</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>221</td>\n",
       "      <td>182</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>128</td>\n",
       "      <td>99</td>\n",
       "      <td>205</td>\n",
       "      <td>73</td>\n",
       "      <td>41</td>\n",
       "      <td>186</td>\n",
       "      <td>138</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    (p) R  R (2)  R (5)  (p) G  G (2)  G (5)  (p) B  B (2)  B (5)  \\\n",
       "0     131    133    135    131    156    159     77     88     82   \n",
       "1      66     23     15     22     16     11      1     16     13   \n",
       "2     221    231    243    221    232    243    225    228    241   \n",
       "3     209    214    225    209    118    134    224    151    168   \n",
       "4     144    202    220    144    214    234    138    206    228   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5     225    205    213    101    207    214    142    211    217   \n",
       "6     216     86     79    217    105     99    220    133    129   \n",
       "7     175     96    117     30     59     71     29     31     35   \n",
       "8     221    182    169     95    128     99    205     73     41   \n",
       "9      84     86     76     51     53     45     25     27     22   \n",
       "\n",
       "    (p) GreyScale  GreyScale (2)  GreyScale (5)  garut  solo  \n",
       "0             125            141            143      1     0  \n",
       "1               0             18             12      0     1  \n",
       "2             212            231            243      1     0  \n",
       "3             204            150            165      1     0  \n",
       "4             140            210            229      1     0  \n",
       "..            ...            ...            ...    ...   ...  \n",
       "5             223            207            214      0     1  \n",
       "6             216            103             96      1     0  \n",
       "7              29             67             81      0     1  \n",
       "8             186            138            113      1     0  \n",
       "9              48             60             52      0     1  \n",
       "\n",
       "[110 rows x 14 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train,df_test])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-2]].values\n",
    "y1 = df[df.columns[-1]].values\n",
    "y2 = df[df.columns[-2]].values\n",
    "Y = pd.DataFrame({\"garut\":y2,\n",
    "                    \"solo\":y1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# data = np.hstack((X, np.reshape(Y, (-1, 1))))\n",
    "data = np.hstack((X, Y))\n",
    "transformed_df = pd.DataFrame(data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(p) R</th>\n",
       "      <th>R (2)</th>\n",
       "      <th>R (5)</th>\n",
       "      <th>(p) G</th>\n",
       "      <th>G (2)</th>\n",
       "      <th>G (5)</th>\n",
       "      <th>(p) B</th>\n",
       "      <th>B (2)</th>\n",
       "      <th>B (5)</th>\n",
       "      <th>(p) GreyScale</th>\n",
       "      <th>GreyScale (2)</th>\n",
       "      <th>GreyScale (5)</th>\n",
       "      <th>garut</th>\n",
       "      <th>solo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137784</td>\n",
       "      <td>0.055752</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.569406</td>\n",
       "      <td>0.814669</td>\n",
       "      <td>0.882016</td>\n",
       "      <td>-0.090073</td>\n",
       "      <td>-0.002329</td>\n",
       "      <td>-0.009424</td>\n",
       "      <td>0.258579</td>\n",
       "      <td>0.507899</td>\n",
       "      <td>0.596410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.704951</td>\n",
       "      <td>-1.554282</td>\n",
       "      <td>-1.342570</td>\n",
       "      <td>-0.975554</td>\n",
       "      <td>-1.310315</td>\n",
       "      <td>-1.163166</td>\n",
       "      <td>-1.078278</td>\n",
       "      <td>-1.087287</td>\n",
       "      <td>-0.963161</td>\n",
       "      <td>-1.181464</td>\n",
       "      <td>-1.427294</td>\n",
       "      <td>-1.256203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304649</td>\n",
       "      <td>1.490147</td>\n",
       "      <td>1.600242</td>\n",
       "      <td>1.845062</td>\n",
       "      <td>1.968232</td>\n",
       "      <td>2.042795</td>\n",
       "      <td>1.834326</td>\n",
       "      <td>2.107313</td>\n",
       "      <td>2.188317</td>\n",
       "      <td>1.260849</td>\n",
       "      <td>1.923893</td>\n",
       "      <td>2.010619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.149067</td>\n",
       "      <td>1.241324</td>\n",
       "      <td>1.367915</td>\n",
       "      <td>1.674974</td>\n",
       "      <td>0.237888</td>\n",
       "      <td>0.536546</td>\n",
       "      <td>1.821323</td>\n",
       "      <td>0.947010</td>\n",
       "      <td>1.179291</td>\n",
       "      <td>1.168686</td>\n",
       "      <td>0.649498</td>\n",
       "      <td>0.907536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306332</td>\n",
       "      <td>1.065683</td>\n",
       "      <td>1.303379</td>\n",
       "      <td>0.753668</td>\n",
       "      <td>1.695020</td>\n",
       "      <td>1.918425</td>\n",
       "      <td>0.703091</td>\n",
       "      <td>1.775798</td>\n",
       "      <td>2.008627</td>\n",
       "      <td>0.431384</td>\n",
       "      <td>1.593494</td>\n",
       "      <td>1.812630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.356510</td>\n",
       "      <td>1.109593</td>\n",
       "      <td>1.213030</td>\n",
       "      <td>0.144188</td>\n",
       "      <td>1.588771</td>\n",
       "      <td>1.642050</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.851142</td>\n",
       "      <td>1.856582</td>\n",
       "      <td>1.387573</td>\n",
       "      <td>1.546294</td>\n",
       "      <td>1.600499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.239824</td>\n",
       "      <td>-0.632172</td>\n",
       "      <td>-0.516517</td>\n",
       "      <td>1.788366</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>1.769313</td>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>1.306931</td>\n",
       "      <td>-0.089966</td>\n",
       "      <td>-0.068268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.708252</td>\n",
       "      <td>-0.485805</td>\n",
       "      <td>-0.026049</td>\n",
       "      <td>-0.862163</td>\n",
       "      <td>-0.657641</td>\n",
       "      <td>-0.334038</td>\n",
       "      <td>-0.714203</td>\n",
       "      <td>-0.861254</td>\n",
       "      <td>-0.659071</td>\n",
       "      <td>-0.847374</td>\n",
       "      <td>-0.656363</td>\n",
       "      <td>-0.280399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.304649</td>\n",
       "      <td>0.772950</td>\n",
       "      <td>0.645119</td>\n",
       "      <td>0.059144</td>\n",
       "      <td>0.389672</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>1.574272</td>\n",
       "      <td>-0.228362</td>\n",
       "      <td>-0.576137</td>\n",
       "      <td>0.961320</td>\n",
       "      <td>0.460699</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-0.471578</td>\n",
       "      <td>-0.632172</td>\n",
       "      <td>-0.555239</td>\n",
       "      <td>-0.564510</td>\n",
       "      <td>-0.748712</td>\n",
       "      <td>-0.693327</td>\n",
       "      <td>-0.766214</td>\n",
       "      <td>-0.921530</td>\n",
       "      <td>-0.838761</td>\n",
       "      <td>-0.628487</td>\n",
       "      <td>-0.766496</td>\n",
       "      <td>-0.690520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        (p) R     R (2)     R (5)     (p) G     G (2)     G (5)     (p) B  \\\n",
       "0    0.137784  0.055752  0.206278  0.569406  0.814669  0.882016 -0.090073   \n",
       "1   -0.704951 -1.554282 -1.342570 -0.975554 -1.310315 -1.163166 -1.078278   \n",
       "2    1.304649  1.490147  1.600242  1.845062  1.968232  2.042795  1.834326   \n",
       "3    1.149067  1.241324  1.367915  1.674974  0.237888  0.536546  1.821323   \n",
       "4    0.306332  1.065683  1.303379  0.753668  1.695020  1.918425  0.703091   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "105  1.356510  1.109593  1.213030  0.144188  1.588771  1.642050  0.755102   \n",
       "106  1.239824 -0.632172 -0.516517  1.788366  0.040568  0.052888  1.769313   \n",
       "107  0.708252 -0.485805 -0.026049 -0.862163 -0.657641 -0.334038 -0.714203   \n",
       "108  1.304649  0.772950  0.645119  0.059144  0.389672  0.052888  1.574272   \n",
       "109 -0.471578 -0.632172 -0.555239 -0.564510 -0.748712 -0.693327 -0.766214   \n",
       "\n",
       "        B (2)     B (5)  (p) GreyScale  GreyScale (2)  GreyScale (5)  garut  \\\n",
       "0   -0.002329 -0.009424       0.258579       0.507899       0.596410    1.0   \n",
       "1   -1.087287 -0.963161      -1.181464      -1.427294      -1.256203    0.0   \n",
       "2    2.107313  2.188317       1.260849       1.923893       2.010619    1.0   \n",
       "3    0.947010  1.179291       1.168686       0.649498       0.907536    1.0   \n",
       "4    1.775798  2.008627       0.431384       1.593494       1.812630    1.0   \n",
       "..        ...       ...            ...            ...            ...    ...   \n",
       "105  1.851142  1.856582       1.387573       1.546294       1.600499    0.0   \n",
       "106  0.675770  0.640222       1.306931      -0.089966      -0.068268    1.0   \n",
       "107 -0.861254 -0.659071      -0.847374      -0.656363      -0.280399    0.0   \n",
       "108 -0.228362 -0.576137       0.961320       0.460699       0.172148    1.0   \n",
       "109 -0.921530 -0.838761      -0.628487      -0.766496      -0.690520    0.0   \n",
       "\n",
       "     solo  \n",
       "0     0.0  \n",
       "1     1.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "..    ...  \n",
       "105   1.0  \n",
       "106   0.0  \n",
       "107   1.0  \n",
       "108   0.0  \n",
       "109   1.0  \n",
       "\n",
       "[110 rows x 14 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_df[transformed_df[\"garut\"]==1]), len(transformed_df[transformed_df[\"solo\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:100].shape\n",
    "Y[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X[:100], Y[:100], test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(12, activation='relu'), # if x <= 0 --> 0, x > 0 --> x\n",
    "                             tf.keras.layers.Dense(24, activation='relu'), #bisa ganti\n",
    "                             tf.keras.layers.Dense(2, activation=\"sigmoid\") #bisa ditambah\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #ganti\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), #ganti\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7514 - accuracy: 0.3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7514148354530334, 0.3499999940395355]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8054 - accuracy: 0.2125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.805378794670105, 0.21250000596046448]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 48ms/step - loss: 0.7493 - accuracy: 0.3500 - val_loss: 0.7878 - val_accuracy: 0.2375\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7347 - accuracy: 0.3500 - val_loss: 0.7712 - val_accuracy: 0.2625\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7208 - accuracy: 0.3500 - val_loss: 0.7556 - val_accuracy: 0.2875\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7084 - accuracy: 0.4000 - val_loss: 0.7409 - val_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6971 - accuracy: 0.4500 - val_loss: 0.7270 - val_accuracy: 0.4250\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6861 - accuracy: 0.4500 - val_loss: 0.7140 - val_accuracy: 0.4875\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6754 - accuracy: 0.5000 - val_loss: 0.7017 - val_accuracy: 0.5750\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6672 - accuracy: 0.6000 - val_loss: 0.6902 - val_accuracy: 0.6375\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6586 - accuracy: 0.6500 - val_loss: 0.6799 - val_accuracy: 0.6750\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6504 - accuracy: 0.6500 - val_loss: 0.6702 - val_accuracy: 0.7125\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6426 - accuracy: 0.6500 - val_loss: 0.6610 - val_accuracy: 0.7375\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6354 - accuracy: 0.8000 - val_loss: 0.6525 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6278 - accuracy: 0.8000 - val_loss: 0.6448 - val_accuracy: 0.7875\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6203 - accuracy: 0.8000 - val_loss: 0.6375 - val_accuracy: 0.7875\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6133 - accuracy: 0.8000 - val_loss: 0.6303 - val_accuracy: 0.7875\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6066 - accuracy: 0.8000 - val_loss: 0.6233 - val_accuracy: 0.8125\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5995 - accuracy: 0.8000 - val_loss: 0.6166 - val_accuracy: 0.8250\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5927 - accuracy: 0.8000 - val_loss: 0.6098 - val_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5857 - accuracy: 0.9500 - val_loss: 0.6030 - val_accuracy: 0.8875\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5794 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5727 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5655 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9125\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5583 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9250\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5508 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.9250\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5433 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.9375\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5354 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.9375\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5272 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.9375\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5195 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5109 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5022 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4937 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4842 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9375\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4754 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4663 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4569 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4471 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4378 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4280 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9625\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4179 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4081 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9625\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3981 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9625\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3885 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9625\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3784 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3687 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9750\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3590 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3494 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9750\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3396 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9875\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3305 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9875\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3207 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3111 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3023 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2930 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2842 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2588 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9875\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2353 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9875\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2279 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9875\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9875\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9875\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9875\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9875\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9875\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1871 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9875\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9875\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9875\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9875\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1645 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9875\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9875\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1497 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9875\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9875\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9875\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9875\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9875\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1248 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9875\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9875\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9875\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9875\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9875\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9875\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9875\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9875\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9875\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9875\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9875\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2658d007190>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=16, epochs=100, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.save of <keras.engine.sequential.Sequential object at 0x000002658BFB5D50>>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.622949  , 0.32708558],\n",
       "       [0.8787025 , 0.11092199],\n",
       "       [0.39861682, 0.5593198 ],\n",
       "       [0.01048894, 0.9742571 ],\n",
       "       [0.8928176 , 0.07951988],\n",
       "       [0.9950997 , 0.00415443],\n",
       "       [0.9955248 , 0.00439631],\n",
       "       [0.04926543, 0.91931605],\n",
       "       [0.9416572 , 0.04675157],\n",
       "       [0.03706929, 0.93853146]], dtype=float32)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persenan =result\n",
    "persenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.hsplit(result,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiri = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanan = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,0] = Garut\n",
      "[1,0] = Garut\n",
      "[0,1] = Solo\n",
      "[0,1] = Solo\n",
      "[1,0] = Garut\n",
      "[1,0] = Garut\n",
      "[1,0] = Garut\n",
      "[0,1] = Solo\n",
      "[1,0] = Garut\n",
      "[0,1] = Solo\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(1):\n",
    "        if kiri[i][j] < kanan[i][j]:\n",
    "            print(\"[0,1] = Solo\")\n",
    "        else:\n",
    "            print(\"[1,0] = Garut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.around(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Garut     Solo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.622949  , 0.32708558],\n",
       "       [0.8787025 , 0.11092199],\n",
       "       [0.39861682, 0.5593198 ],\n",
       "       [0.01048894, 0.9742571 ],\n",
       "       [0.8928176 , 0.07951988],\n",
       "       [0.9950997 , 0.00415443],\n",
       "       [0.9955248 , 0.00439631],\n",
       "       [0.04926543, 0.91931605],\n",
       "       [0.9416572 , 0.04675157],\n",
       "       [0.03706929, 0.93853146]], dtype=float32)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"        Garut     Solo\")\n",
    "persenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Garut     Solo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.622949  , 0.32708558],\n",
       "       [0.8787025 , 0.11092199],\n",
       "       [0.39861682, 0.5593198 ],\n",
       "       [0.01048894, 0.9742571 ],\n",
       "       [0.8928176 , 0.07951988],\n",
       "       [0.9950997 , 0.00415443],\n",
       "       [0.9955248 , 0.00439631],\n",
       "       [0.04926543, 0.91931605],\n",
       "       [0.9416572 , 0.04675157],\n",
       "       [0.03706929, 0.93853146]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"        Garut     Solo\")\n",
    "persenan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
